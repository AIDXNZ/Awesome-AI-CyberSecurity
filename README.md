<img src="https://bafybeifvc2mcyyyj2hrymxdpw7xcqfdnyayira44jibdqcy6njefdwdo4y.ipfs.w3s.link/ecSQ2THC.jpeg" width="1000">

# Awesome-AI-CyberSecurity
A collection of resources to start off researching AI in CyberSecurity

### Contributions welcome
If you want to contribute to this list, by all means. 

### Check out also
* [awesome-cyber-security](https://github.com/fabionoth/awesome-cyber-security) - A curated list of Cyber Sec resources

# Table of Contents
- Basic Introduction
- Articles

# Basic Introduction
To help classify and aggergrate research there will be 4 main categories for this repo:

1. Exploiting the Training Process or at Data collection
   - Refered to as poisoning, is the process of injecting maliscous or faulty data to a Machine Learning model.
2. Exploiting a Pre-trained model
   - Refers to exploiting a ML's input to get a desired output. 
3. ML/AI Supported hacking
   - Refers to offensive hacking use AI/ML tools. 
4. ML/AI Supported Security
   - Refers to Information Security use of AI/ML tools.

## Problems in AI and Machine Learning Models
There are numerous amounts of ways to exploit a machine learning model. Most of which can be summed down into these categories. 

Evasion attacks - Hackers provide faulty algorithm inputs, leading to incorrect decisions.

Poisoning attacks - Hackers provide poisoned data for training sets. which corrupt the machine learning algorithm and spoil the data mining process.

Inference attacks - Hackers use the training phase to try and retrieve private data.

Extraction attacks - Hackers steal the Machine Learning model

## What are Evasion attacks?
Evasion attacks are essentially prividing the model with an input and getting an output.Some really good examples are what users are doing with ChatGPT3. There are 'strict' guidelines for the model to follow but with a simple "convincing" statement the chatbot will break those rules for you. 


# Articles 

### Arxiv.org
- Explaining and Harnessing Advesarial Examples [Source](https://arxiv.org/abs/1412.6572)


### IEEE.org
- Ethics and Privacy in AI and Big Data: Implementing Responsible Research and Innovation [Source](https://ieeexplore.ieee.org/document/8395078")
- Federated Learning With Differential Privacy: Algorithms and Performance Analysis [Source](https://ieeexplore.ieee.org/document/9069945)
- PAST-AI: Physical-Layer Authentication of Satellite Transmitters via Deep Learning [Source](https://ieeexplore.ieee.org/document/9936663)
- Privacy-Preserving Deep Learning via Additively Homomorphic Encryption [Source](https://ieeexplore.ieee.org/document/8241854)
- Exploring Bias in Sclera Segmentation Models: A Group Evaluation Approach [Source](https://ieeexplore.ieee.org/document/9926136)
- Occlusion-Aware Human Mesh Model-Based Gait Recognition [Source](https://ieeexplore.ieee.org/document/10015098)

### TrendMicro
- How Cybercriminals Misuse and Abuse AI and ML [Source](https://www.trendmicro.com/vinfo/us/security/news/cybercrime-and-digital-threats/exploiting-ai-how-cybercriminals-misuse-abuse-ai-and-ml)
- 
